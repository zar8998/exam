{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvdJl_E1TK3m",
        "outputId": "0bd9b13c-9e26-4ff5-f18e-92919f628df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 20.13 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JziVSWgeh9xN",
        "outputId": "37c43b3c-b45f-4671-9f35-cd3e87eff636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Knee-X-ray' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "root_dir = \"/content/Knee-X-ray\"\n",
        "\n",
        "for root, dirs, files in os.walk(root_dir):\n",
        "    level = root.replace(root_dir, '').count(os.sep)\n",
        "    indent = ' ' * 4 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    sub_indent = ' ' * 4 * (level + 1)\n",
        "    for f in files[:5]:\n",
        "        print(f\"{sub_indent}{f}\")\n"
      ],
      "metadata": {
        "id": "xcKK2pV8h9z_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ø§Ù„Ø§Ù† Ø´Ù…Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù…Ø®Ø²Ù† `Knee-X-ray` Ø±Ùˆ Ø¯Ùˆ Ø¨Ø§Ø± Ú©Ù„ÙˆÙ† Ú©Ø±Ø¯ÛŒØ¯ØŒ ÙˆÙ„ÛŒ Ù‡Ù†ÙˆØ² Ú†ÛŒØ²ÛŒ Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ Ø§ÙˆÙ† Ù†Ø´ÙˆÙ† Ù†Ø¯Ø§Ø¯ÛŒØŒ Ù¾Ø³ Ù†Ù…ÛŒâ€ŒØ¯ÙˆÙ†ÛŒÙ… ØªØµØ§ÙˆÛŒØ± Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ú©Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Ù„Ø·ÙØ§Ù‹ Ø§ÛŒÙ† Ú©Ø¯ Ø±Ø§ Ù‡Ù…ÛŒÙ† Ø§Ù„Ø§Ù† Ø§Ø¬Ø±Ø§ Ú©Ù† ØªØ§ Ø³Ø§Ø®ØªØ§Ø± ÙÙˆÙ„Ø¯Ø±Ù‡Ø§ Ø±Ø§ Ú†Ø§Ù¾ Ú©Ù†ÛŒÙ…:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "root_dir = \"/content/Knee-X-ray\"\n",
        "\n",
        "for root, dirs, files in os.walk(root_dir):\n",
        "    level = root.replace(root_dir, '').count(os.sep)\n",
        "    indent = ' ' * 4 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    sub_indent = ' ' * 4 * (level + 1)\n",
        "    for f in files[:5]:\n",
        "        print(f\"{sub_indent}{f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### â­ Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¬Ø±Ø§:\n",
        "\n",
        "Ø®Ø±ÙˆØ¬ÛŒâ€ŒØ§ÛŒ Ø´Ø¨ÛŒÙ‡ Ø§ÛŒÙ† Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒØ¯:\n",
        "\n",
        "```\n",
        "Knee-X-ray/\n",
        "    dataset/\n",
        "        Normal/\n",
        "            image001.png\n",
        "        AbNormal/\n",
        "            image101.png\n",
        "```\n",
        "\n",
        "ÙˆÙ‚ØªÛŒ Ø§ÛŒÙ† Ø®Ø±ÙˆØ¬ÛŒ Ø±Ùˆ Ø§ÛŒÙ†Ø¬Ø§ Ø¨ÙØ±Ø³ØªÛŒØŒ Ø¯Ù‚ÛŒÙ‚ Ù…ÛŒâ€ŒÚ¯Ù… Ù…Ø³ÛŒØ± `dataset_path` Ø¨Ø§ÛŒØ¯ Ú†ÛŒ Ø¨Ø§Ø´Ù‡ Ùˆ Ø¨Ø¹Ø¯ Ø¨Ø±ÛŒÙ… Ø³Ø±Ø§Øº Ø³Ø§Ø®Øª `Custom Dataset` + Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ ØªØµØ§ÙˆÛŒØ± + Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„.\n",
        "\n",
        "Ø¨ÙØ±Ø³Øª ØªØ§ Ø¨Ø±ÛŒÙ… Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "4J1fheH2h93C",
        "outputId": "a086c9ee-a59e-4f3d-eaa7-fc7598e3a56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character 'ØŒ' (U+060C) (<ipython-input-2-0eb82e7166a9>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0eb82e7166a9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Ø§Ù„Ø§Ù† Ø´Ù…Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù…Ø®Ø²Ù† `Knee-X-ray` Ø±Ùˆ Ø¯Ùˆ Ø¨Ø§Ø± Ú©Ù„ÙˆÙ† Ú©Ø±Ø¯ÛŒØ¯ØŒ ÙˆÙ„ÛŒ Ù‡Ù†ÙˆØ² Ú†ÛŒØ²ÛŒ Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ Ø§ÙˆÙ† Ù†Ø´ÙˆÙ† Ù†Ø¯Ø§Ø¯ÛŒØŒ Ù¾Ø³ Ù†Ù…ÛŒâ€ŒØ¯ÙˆÙ†ÛŒÙ… ØªØµØ§ÙˆÛŒØ± Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ú©Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯.\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character 'ØŒ' (U+060C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GJ7lQXQXh96P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CuAyXVg7h99o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogVpl9Yvcf07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "!apt install unrar -y > /dev/null\n",
        "!unrar x /content/Knee-X-ray/train.rar /content/Knee-X-ray/train > /dev/null\n",
        "!unrar x /content/Knee-X-ray/val.rar /content/Knee-X-ray/val > /dev/null\n",
        "!unrar x /content/Knee-X-ray/test.rar /content/Knee-X-ray/test > /dev/null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td7g8_F_TKs3",
        "outputId": "36dbb5de-1b28-4721-882b-7547d513ec70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 11.83 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/Knee-X-ray/train/train\"\n",
        "val_path = \"/content/Knee-X-ray/val/val\""
      ],
      "metadata": {
        "id": "nAgS3LHOTKoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø§Ú¯Ø± Ù‡Ù†ÙˆØ² Ù†Ú©Ø±Ø¯ÛŒØŒ Ø§Ø¨ØªØ¯Ø§ Ú¯ÛŒØª Ú©Ù„ÙˆÙ† Ú©Ù†\n",
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "\n",
        "# Ù†ØµØ¨ unrar Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ rar\n",
        "!apt install unrar -y > /dev/null\n",
        "\n",
        "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ rar Ø¨Ù‡ ÙÙˆÙ„Ø¯Ø±Ù‡Ø§ÛŒ Ø¬Ø¯Ø§\n",
        "!unrar x /content/Knee-X-ray/train.rar /content/Knee-X-ray/train > /dev/null\n",
        "!unrar x /content/Knee-X-ray/val.rar /content/Knee-X-ray/val > /dev/null\n",
        "!unrar x /content/Knee-X-ray/test.rar /content/Knee-X-ray/test > /dev/null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d_cMubzTKdo",
        "outputId": "b8c154c6-7ef0-40c3-b168-6a1f35c313dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 13.38 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“¦ Ù†ØµØ¨ Ùˆ Ø¨Ø§Ø±Ú¯ÛŒØ±ÛŒ Ø§ÙˆÙ„ÛŒÙ‡\n",
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# ğŸ“ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµØ§ÙˆÛŒØ±\n",
        "def load_images(base_path):\n",
        "    images, labels = [], []\n",
        "    for label_name in ['Normal', 'Abnormal']:\n",
        "        folder = os.path.join(base_path, label_name)\n",
        "        for img_name in os.listdir(folder):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            img = cv2.equalizeHist(img)  # Ø§ÙØ²Ø§ÛŒØ´ Ú©Ù†ØªØ±Ø§Ø³Øª\n",
        "            img = img / 255.0  # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
        "            images.append(img.reshape(224, 224, 1))\n",
        "            labels.append(0 if label_name == 'Normal' else 1)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "images, labels = load_images('Knee-X-ray/dataset')\n",
        "\n",
        "# âœ… Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "# ğŸ§ª ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "# Ø¨Ø®Ø´ B - Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
        "\n",
        "# ğŸ“Œ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†ØªÛŒ (SVM Ùˆ Random Forest)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_flat, y_train)\n",
        "svm_preds = svm_model.predict(X_test_flat)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X_train_flat, y_train)\n",
        "rf_preds = rf_model.predict(X_test_flat)\n",
        "\n",
        "# ğŸ“Œ Ù…Ø¯Ù„ CNN Ø³Ø§Ø¯Ù‡\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "cnn_preds = (cnn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# ğŸ“Œ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ Ø¨Ø§ ResNet50\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "tl_model = Model(inputs=base_model.input, outputs=output)\n",
        "tl_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "tl_model.fit(X_train_rgb, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "tl_preds = (tl_model.predict(X_test_rgb) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Ø¨Ø®Ø´ C - Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
        "\n",
        "def get_scores(y_true, y_pred):\n",
        "    return {\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'F1-score': f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "results = {\n",
        "    'Model': ['SVM', 'Random Forest', 'CNN', 'ResNet50 Transfer'],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'Accuracy': [],\n",
        "    'F1-score': []\n",
        "}\n",
        "\n",
        "model_preds = [svm_preds, rf_preds, cnn_preds, tl_preds]\n",
        "for preds in model_preds:\n",
        "    scores = get_scores(y_test, preds)\n",
        "    for key in scores:\n",
        "        results[key].append(scores[key])\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ¯ Ú†Ø±Ø§ F1-scoreØŸ\n",
        "F1-score Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡Ù…Ø§Ù‡Ù†Ú¯ Precision Ùˆ Recall Ø§Ø³Øª Ùˆ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ØªÙˆØ§Ø²Ù† Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª.\n",
        "Ø¯Ø± ÙˆØ¸ÛŒÙÙ‡ Ù¾Ø²Ø´Ú©ÛŒØŒ Ø¨Ù‡â€ŒÙˆÛŒÚ˜Ù‡ ÙˆÙ‚ØªÛŒ Ú©Ù‡ Ø¹Ø¯Ù… ØªØ´Ø®ÛŒØµ ÛŒÚ© Ø¨ÛŒÙ…Ø§Ø± (False Negative) Ø®Ø·Ø±Ù†Ø§Ú© Ø§Ø³ØªØŒ\n",
        "F1-score Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±ÛŒ Ø§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ù†Ø³Ø¨Øª Ø¨Ù‡ Accuracy Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.\n",
        "\"\"\")\n",
        "\n",
        "# âœ… Ø¹Ø¯Ø§Ù„Øª Ùˆ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ù…Ø¯Ù„:\n",
        "print(\"\"\"\n",
        "ğŸ”’ Ú†Ú¯ÙˆÙ†Ù‡ Ù…Ø¯Ù„ Ø¹Ø§Ø¯Ù„Ø§Ù†Ù‡ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¨Ø³Ø§Ø²ÛŒÙ…ØŸ\n",
        "- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Stratified Split Ùˆ Cross-Validation\n",
        "- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÚ©Ù†ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Overfitting\n",
        "- ØªÙ†Ø¸ÛŒÙ… ÙˆØ²Ù† Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Oversampling\n",
        "- ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ø²ÛŒØ±Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¨ÛŒÙ…Ø§Ø±Ø§Ù† (Ù…Ø«Ù„Ø§Ù‹ Ø³Ù†ØŒ Ø¬Ù†Ø³ÛŒØª)\n",
        "\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "7OD3oDm1gpRX",
        "outputId": "add84075-045f-4dfd-d7f0-3b0f7bb5bd6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 16.19 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Knee-X-ray/dataset/Normal'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0e70d6010200>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Knee-X-ray/dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# âœ… Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-0e70d6010200>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Abnormal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Knee-X-ray/dataset/Normal'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/Knee-X-ray/train/train\"\n",
        "val_path = \"/content/Knee-X-ray/val/val\"\n"
      ],
      "metadata": {
        "id": "zA2wyseETKbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØµØ§ÙˆÛŒØ± Ø¢Ù…ÙˆØ²Ø´ (ØªØ§ Ù…Ø¯Ù„ Ø¨Ù‡ØªØ± ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±Ù‡)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,        # Ù‡Ù…Ù‡ Ù¾ÛŒÚ©Ø³Ù„â€ŒÙ‡Ø§ Ø±Ùˆ Ø¨ÛŒÙ† 0 Ùˆ 1 Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n",
        "    rotation_range=10,     # Ú†Ø±Ø®Ø´ ØªØµÙˆÛŒØ± ØªØ§ 10 Ø¯Ø±Ø¬Ù‡\n",
        "    width_shift_range=0.1, # Ø¬Ø§Ø¨Ø¬Ø§ÛŒÛŒ Ø¹Ø±Ø¶ÛŒ ØªØ§ 10 Ø¯Ø±ØµØ¯\n",
        "    height_shift_range=0.1,# Ø¬Ø§Ø¨Ø¬Ø§ÛŒÛŒ Ø§Ø±ØªÙØ§Ø¹ÛŒ ØªØ§ 10 Ø¯Ø±ØµØ¯\n",
        "    brightness_range=[0.8,1.2], # ØªØºÛŒÛŒØ± Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ\n",
        "    horizontal_flip=True,  # Ú†Ø±Ø®Ø´ Ø§ÙÙ‚ÛŒ ØªØµÙˆÛŒØ±\n",
        "    fill_mode='nearest'    # Ù¾Ø± Ú©Ø±Ø¯Ù† Ø¬Ø§Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ ØªØµÙˆÛŒØ±\n",
        ")\n",
        "\n",
        "# ÙÙ‚Ø· Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªØµØ§ÙˆÛŒØ± Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ (Ø¨Ø¯ÙˆÙ† Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Ø³Ø§Ø®Øª Ú˜Ù†Ø±Ø§ØªÙˆØ± Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224,224), # Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµØ§ÙˆÛŒØ±\n",
        "    batch_size=32,         # ØªØ¹Ø¯Ø§Ø¯ ØªØµÙˆÛŒØ± Ø¯Ø± Ù‡Ø± Ù…Ø±Ø­Ù„Ù‡\n",
        "    class_mode='binary',   # Ø¯Ùˆ Ú©Ù„Ø§Ø³ Ø¯Ø§Ø±ÛŒÙ…\n",
        "    color_mode='grayscale' # ØªØµØ§ÙˆÛŒØ± Ø³ÛŒØ§Ù‡ Ùˆ Ø³ÙÛŒØ¯ Ù‡Ø³ØªÙ†Ø¯\n",
        ")\n",
        "\n",
        "# Ø³Ø§Ø®Øª Ú˜Ù†Ø±Ø§ØªÙˆØ± Ø¨Ø±Ø§ÛŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    color_mode='grayscale'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "7Hsmlc2MbAI_",
        "outputId": "808a3961-bcbe-43ab-8579-2b0dfa90c60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Knee-X-ray/train/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-643f840ce7c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Ø³Ø§Ø®Øª Ú˜Ù†Ø±Ø§ØªÙˆØ± Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµØ§ÙˆÛŒØ±\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Knee-X-ray/train/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# === ØªØ­Ù„ÛŒÙ„ Ù…Ù‚Ø¯Ù…Ø§ØªÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ===\n",
        "\n",
        "# Ù…Ø³ÛŒØ± ØªØµØ§ÙˆÛŒØ± Ø³Ø§Ù„Ù… Ùˆ ØºÛŒØ±Ø³Ø§Ù„Ù…\n",
        "normal_images = glob(\"Knee-X-ray/Normal/*.png\")\n",
        "abnormal_images = glob(\"Knee-X-ray/Abnormal/*.png\")\n",
        "\n",
        "print(f\"ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ø³Ø§Ù„Ù…: {len(normal_images)}\")\n",
        "print(f\"ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± ØºÛŒØ±Ø³Ø§Ù„Ù…: {len(abnormal_images)}\")\n",
        "\n",
        "# Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡ ØªØµÙˆÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡\n",
        "def show_sample(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(\"Sample X-ray\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_sample(normal_images[0])\n",
        "\n",
        "\n",
        "# === Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´: Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø­Ø°Ù Ù†ÙˆÛŒØ² ===\n",
        "\n",
        "def preprocess_image(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ: ØªØ¨Ø¯ÛŒÙ„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒÚ©Ø³Ù„ Ø¨Ù‡ [0, 1]\n",
        "    img = img / 255.0\n",
        "\n",
        "    # ÙÛŒÙ„ØªØ± Ú¯ÙˆØ³ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ù†ÙˆÛŒØ² Ù†ÙˆØ±ÛŒ\n",
        "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "\n",
        "    return img\n",
        "\n",
        "# Ù†Ù…Ø§ÛŒØ´ ØªØµÙˆÛŒØ± Ù‚Ø¨Ù„ Ùˆ Ø¨Ø¹Ø¯ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´\n",
        "original = cv2.imread(normal_images[0], cv2.IMREAD_GRAYSCALE)\n",
        "processed = preprocess_image(normal_images[0])\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(original, cmap='gray')\n",
        "plt.title(\"Original\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(processed, cmap='gray')\n",
        "plt.title(\"Processed\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# === ØªÙˆØ¬ÛŒÙ‡ Ø±ÛŒØ§Ø¶ÛŒ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ===\n",
        "\n",
        "\"\"\"\n",
        "ÙØ±Ù…ÙˆÙ„ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ØªØµÙˆÛŒØ±:\n",
        "\n",
        "    Normalized = I / 255\n",
        "\n",
        "Ú©Ù‡ Ø¯Ø± Ø¢Ù† I Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒÚ©Ø³Ù„ Ø®Ø§Ù… Ø¨ÛŒÙ† 0 ØªØ§ 255 Ø§Ø³Øª.\n",
        "Ø§ÛŒÙ† Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§Ø¹Ø« Ù¾Ø§ÛŒØ¯Ø§Ø± Ø´Ø¯Ù† Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ùˆ ØªØ³Ø±ÛŒØ¹ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# === Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ (Data Augmentation) ===\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,        # Ú†Ø±Ø®Ø´ Ø¬Ø²Ø¦ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ†ÙˆØ¹ Ø²Ø§ÙˆÛŒÙ‡\n",
        "    width_shift_range=0.05,   # Ø¬Ø§Ø¨Ù‡â€ŒØ¬Ø§ÛŒÛŒ Ø¹Ø±Ø¶ÛŒ\n",
        "    height_shift_range=0.05,  # Ø¬Ø§Ø¨Ù‡â€ŒØ¬Ø§ÛŒÛŒ Ø·ÙˆÙ„ÛŒ\n",
        "    zoom_range=0.1,           # Ø¨Ø²Ø±Ú¯â€ŒÙ†Ù…Ø§ÛŒÛŒ Ø¬Ø²Ø¦ÛŒ\n",
        "    horizontal_flip=True,     # ØªÙ‚Ø§Ø±Ù† Ø§ÙÙ‚ÛŒ\n",
        "    brightness_range=[0.9, 1.1] # Ø§ÙØ²Ø§ÛŒØ´/Ú©Ø§Ù‡Ø´ Ø±ÙˆØ´Ù†Ø§ÛŒÛŒ\n",
        ")\n",
        "\n",
        "# Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡\n",
        "img = preprocess_image(normal_images[0])\n",
        "img = np.expand_dims(img, axis=(0, -1))  # Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ ImageDataGenerator\n",
        "\n",
        "aug_iter = datagen.flow(img, batch_size=1)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(5):\n",
        "    aug_img = next(aug_iter)[0].squeeze()\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(aug_img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Aug {i+1}\")\n",
        "plt.suptitle(\"Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "S2Ao9ieBcYlL",
        "outputId": "c9d80531-5aab-430b-c224-bbd08f9096f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± Ø³Ø§Ù„Ù…: 0\n",
            "ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± ØºÛŒØ±Ø³Ø§Ù„Ù…: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-376bc4ce5699>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mshow_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ÙØ±Ø¶: data_images = [N, 224, 224] Ùˆ labels = [0/1]\n",
        "# Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² Ù…Ø±Ø­Ù„Ù‡ A Ø¨Ø§ÛŒØ¯ ØªÙˆÙ„ÛŒØ¯ Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´ÛŒØ¯.\n",
        "\n",
        "# Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„ Ø³Ø§Ø®ØªÚ¯ÛŒ:\n",
        "# data_images = np.array([...])\n",
        "# labels = np.array([0, 1, 0, 1, ...])\n",
        "\n",
        "# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ø¹Ø¯ Ú©Ø§Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ CNN\n",
        "data_images = np.expand_dims(data_images, axis=-1)\n",
        "\n",
        "# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ train Ùˆ test\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_images, labels, test_size=0.2, random_state=42, stratify=labels)\n"
      ],
      "metadata": {
        "id": "CYHnlAI4ftZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Ø¨Ø±Ø§ÛŒ ML Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ØµÙˆØ±Øª ÙÙ„Øª (ÙˆÛŒÚ˜Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ÛŒÚ© Ø®Ø·) Ø¨Ø§Ø´Ù†Ø¯\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Ù…Ù‚ÛŒØ§Ø³â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# Ù…Ø¯Ù„ SVM\n",
        "svm_model = SVC(kernel='rbf', C=1.0)\n",
        "svm_model.fit(X_train_flat, y_train)\n",
        "svm_preds = svm_model.predict(X_test_flat)\n",
        "\n",
        "# Ù…Ø¯Ù„ Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X_train_flat, y_train)\n",
        "rf_preds = rf_model.predict(X_test_flat)\n",
        "\n",
        "# Ú¯Ø²Ø§Ø±Ø´\n",
        "print(\"SVM Report:\")\n",
        "print(classification_report(y_test, svm_preds))\n",
        "\n",
        "print(\"Random Forest Report:\")\n",
        "print(classification_report(y_test, rf_preds))\n",
        "\n"
      ],
      "metadata": {
        "id": "LZWXCd7pfuo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "cnn_scores = cnn_model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"CNN Accuracy:\", cnn_scores[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "ujjyEiojf0ak",
        "outputId": "2923e75d-8421-41c3-df17-20c18dd4b209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-47b8f3d688d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mcnn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3 Ú©Ø§Ù†Ø§Ù„Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡\n",
        "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "base_model.trainable = False  # ÙØ±ÛŒØ² Ú©Ø±Ø¯Ù† Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "tl_model = Model(inputs=base_model.input, outputs=output)\n",
        "tl_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                 loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "tl_model.fit(X_train_rgb, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "tl_scores = tl_model.evaluate(X_test_rgb, y_test)\n",
        "\n",
        "print(\"Transfer Learning Accuracy:\", tl_scores[1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ErS6X59qf8s6",
        "outputId": "4a7e16d1-edaf-4241-e826-f0d64fe793af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c7de73ef8cb5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ 3 Ú©Ø§Ù†Ø§Ù„Ù‡ Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø¯Ù‡\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_test_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§© Ù…Ø±Ø­Ù„Ù‡ 1: Ú©Ù„ÙˆÙ† Ú©Ø±Ø¯Ù† Ø¯ÛŒØªØ§Ø³Øª\n",
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "\n",
        "# ğŸ§¹ Ù…Ø±Ø­Ù„Ù‡ 2: ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ğŸ“‚ Ù…Ø±Ø­Ù„Ù‡ 3: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±\n",
        "def load_images(base_path):\n",
        "    images, labels = [], []\n",
        "    for label_name in ['Normal', 'Abnormal']:\n",
        "        folder = os.path.join(base_path, label_name)\n",
        "        if not os.path.exists(folder):\n",
        "            print(f\"â›” Ù¾ÙˆØ´Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: {folder}\")\n",
        "            continue\n",
        "        for img_name in os.listdir(folder):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            img = cv2.equalizeHist(img)      # Ø§ÙØ²Ø§ÛŒØ´ Ú©Ù†ØªØ±Ø§Ø³Øª\n",
        "            img = img / 255.0                # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ\n",
        "            images.append(img.reshape(224, 224, 1))\n",
        "            labels.append(0 if label_name == 'Normal' else 1)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "images, labels = load_images('Knee-X-ray/dataset')\n",
        "\n",
        "# ğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 4: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# ğŸ§  Ù…Ø±Ø­Ù„Ù‡ 5: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†ØªÛŒ\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_flat, y_train)\n",
        "svm_preds = svm_model.predict(X_test_flat)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X_train_flat, y_train)\n",
        "rf_preds = rf_model.predict(X_test_flat)\n",
        "\n",
        "# ğŸ§  Ù…Ø±Ø­Ù„Ù‡ 6: Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ Ú©Ø§Ù†ÙˆÙ„ÙˆØ´Ù†ÛŒ (CNN)\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "cnn_preds = (cnn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# ğŸ§  Ù…Ø±Ø­Ù„Ù‡ 7: ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ Ø¨Ø§ ResNet50\n",
        "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "tl_model = Model(inputs=base_model.input, outputs=output)\n",
        "tl_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "tl_model.fit(X_train_rgb, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "tl_preds = (tl_model.predict(X_test_rgb) > 0.5).astype(\"int32\")\n",
        "\n",
        "# ğŸ“ˆ Ù…Ø±Ø­Ù„Ù‡ 8: Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§\n",
        "def get_scores(y_true, y_pred):\n",
        "    return {\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'F1-score': f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "results = {\n",
        "    'Model': ['SVM', 'Random Forest', 'CNN', 'ResNet50 Transfer'],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'Accuracy': [],\n",
        "    'F1-score': []\n",
        "}\n",
        "\n",
        "model_preds = [svm_preds, rf_preds, cnn_preds, tl_preds]\n",
        "for preds in model_preds:\n",
        "    scores = get_scores(y_test, preds)\n",
        "    for key in scores:\n",
        "        results[key].append(scores[key])\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"ğŸ“Š Ø¬Ø¯ÙˆÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§:\")\n",
        "print(df)\n",
        "\n",
        "# ğŸ“Œ ØªØ­Ù„ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "print(\"\"\"\n",
        "âœ… Ú†Ø±Ø§ F1-scoreØŸ\n",
        "F1-score Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ØªÙˆØ§Ø²Ù† Ø¨Ù‡ØªØ± Ø§Ø² Accuracy Ø§Ø³ØªØŒ Ú†ÙˆÙ† ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø² Precision Ùˆ Recall Ø§Ø³Øª.\n",
        "Ø¯Ø± Ú©Ø§Ø±Ø¨Ø±Ø¯ Ù¾Ø²Ø´Ú©ÛŒØŒ Ø¹Ø¯Ù… ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø± (False Negative) Ø®Ø·Ø±Ù†Ø§Ú© Ø§Ø³ØªØŒ Ù¾Ø³ F1-score Ù…Ø¹ÛŒØ§Ø± Ù‚Ø§Ø¨Ù„â€ŒØ§ØªÚ©Ø§ØªØ±ÛŒ Ù…Ø­Ø³ÙˆØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯.\n",
        "\n",
        "âœ… Ú†Ø·ÙˆØ± Ù…Ø¯Ù„ Ø±Ø§ Ù‚Ø§Ø¨Ù„â€ŒØ§Ø¹ØªÙ…Ø§Ø¯ØªØ± Ú©Ù†ÛŒÙ…ØŸ\n",
        "- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Cross-validation ÛŒØ§ Stratified split\n",
        "- Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Overfitting Ø¨Ø§ EarlyStoppingØŒ Dropout\n",
        "- Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ø²ÛŒØ±Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¬Ù…Ø¹ÛŒØª (Ø³Ù†ØŒ Ø¬Ù†Ø³ÛŒØª)\n",
        "- ØªÙ†Ø¸ÛŒÙ… ÙˆØ²Ù† Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SMOTE Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†ØªÛŒ\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4um9hrO7gGLT",
        "outputId": "3ddd7b09-49e4-47f8-e013-70d6e45c472b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Knee-X-ray' already exists and is not an empty directory.\n",
            "â›” Ù¾ÙˆØ´Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: Knee-X-ray/dataset/Normal\n",
            "â›” Ù¾ÙˆØ´Ù‡ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯: Knee-X-ray/dataset/Abnormal\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-edaf4b7e4824>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# ğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 4: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m datagen = ImageDataGenerator(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸš€ Ù…Ø±Ø­Ù„Ù‡ 1: Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ú©Ù„ÙˆÙ† Ø¯ÛŒØªØ§Ø³Øª\n",
        "!rm -rf Knee-X-ray\n",
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "\n",
        "# ğŸ“¦ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ğŸ“‚ Ù…Ø±Ø­Ù„Ù‡ 2: ÛŒØ§ÙØªÙ† Ù…Ø³ÛŒØ± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§\n",
        "def find_dataset_path(base_dir='Knee-X-ray'):\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        if 'Normal' in dirs and 'Abnormal' in dirs:\n",
        "            return root\n",
        "    raise Exception(\"âŒ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Normal Ùˆ Abnormal Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯.\")\n",
        "\n",
        "dataset_path = find_dataset_path()\n",
        "\n",
        "# ğŸ§¹ Ù…Ø±Ø­Ù„Ù‡ 3: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±\n",
        "def load_images(base_path):\n",
        "    images, labels = [], []\n",
        "    for label_name in ['Normal', 'Abnormal']:\n",
        "        folder = os.path.join(base_path, label_name)\n",
        "        for img_name in os.listdir(folder):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            img = cv2.equalizeHist(img)\n",
        "            img = img / 255.0\n",
        "            images.append(img.reshape(224, 224, 1))\n",
        "            labels.append(0 if label_name == 'Normal' else 1)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "images, labels = load_images(dataset_path)\n",
        "\n",
        "# ğŸ”„ Ù…Ø±Ø­Ù„Ù‡ 4: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ + Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# ğŸ¯ Ù…Ø±Ø­Ù„Ù‡ 5: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø³Ù†ØªÛŒ (SVM + RandomForest)\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train_flat, y_train)\n",
        "svm_preds = svm.predict(X_test_flat)\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_flat, y_train)\n",
        "rf_preds = rf.predict(X_test_flat)\n",
        "\n",
        "# ğŸ§  Ù…Ø±Ø­Ù„Ù‡ 6: Ø´Ø¨Ú©Ù‡ CNN Ø³Ø§Ø¯Ù‡\n",
        "cnn = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "cnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "cnn_preds = (cnn.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# ğŸ§  Ù…Ø±Ø­Ù„Ù‡ 7: ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ÛŒ Ø¨Ø§ ResNet50\n",
        "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "base = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "base.trainable = False\n",
        "x = GlobalAveragePooling2D()(base.output)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "resnet_model = Model(inputs=base.input, outputs=output)\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "resnet_model.fit(X_train_rgb, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "resnet_preds = (resnet_model.predict(X_test_rgb) > 0.5).astype(\"int32\")\n",
        "\n",
        "# ğŸ“ˆ Ù…Ø±Ø­Ù„Ù‡ 8: Ú¯Ø²Ø§Ø±Ø´ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n",
        "def get_scores(y_true, y_pred):\n",
        "    return {\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'F1-score': f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "results = {\n",
        "    'Model': ['SVM', 'Random Forest', 'CNN', 'ResNet50 Transfer'],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'Accuracy': [],\n",
        "    'F1-score': []\n",
        "}\n",
        "for preds in [svm_preds, rf_preds, cnn_preds, resnet_preds]:\n",
        "    scores = get_scores(y_test, preds)\n",
        "    for key in scores:\n",
        "        results[key].append(scores[key])\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"ğŸ“Š Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§:\\n\")\n",
        "print(df)\n",
        "\n",
        "# ğŸ“ ØªÙˆØ¶ÛŒØ­ Ù†Ù‡Ø§ÛŒÛŒ\n",
        "print(\"\"\"\n",
        "âœ… Ú†Ø±Ø§ F1-score Ù…Ù‡Ù… Ø§Ø³ØªØŸ\n",
        "F1-score Ù‡Ù… ØªØ¹Ø§Ø¯Ù„ Precision Ùˆ Ù‡Ù… Recall Ø±Ø§ Ø¯Ø±Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯. Ø¯Ø± Ù…Ø³Ø§Ø¦Ù„ Ù¾Ø²Ø´Ú©ÛŒ Ù…Ø§Ù†Ù†Ø¯ ØªØ´Ø®ÛŒØµ Ø¨ÛŒÙ…Ø§Ø±ÛŒØŒ Ø§Ú¯Ø± ÙÙ‚Ø· Ø¯Ù‚Øª ÛŒØ§ ÙÙ‚Ø· Recall Ù…Ù‡Ù… Ø¨Ø§Ø´Ø¯ØŒ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨ÛŒÙ…Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù†Ø´ÙˆØ¯ ÛŒØ§ ÙØ±Ø¯ Ø³Ø§Ù„Ù… Ø¨Ù‡ Ø§Ø´ØªØ¨Ø§Ù‡ Ø¨ÛŒÙ…Ø§Ø± Ø§Ø¹Ù„Ø§Ù… Ø´ÙˆØ¯.\n",
        "\n",
        "âœ… Ú†Ø·ÙˆØ± Ù…Ø¯Ù„ Ø±Ø§ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ØªØ± Ú©Ù†ÛŒÙ…ØŸ\n",
        "- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Stratified Split\n",
        "- EarlyStopping Ùˆ Dropout Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Overfitting\n",
        "- Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø±ÙˆÛŒ Ø²ÛŒØ±Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ (Ù…Ø§Ù†Ù†Ø¯ Ø¬Ù†Ø³ÛŒØª ÛŒØ§ Ø³Ù†)\n",
        "- Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø­ÙØ¸ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ØªØµØ§ÙˆÛŒØ± Ù¾Ø²Ø´Ú©ÛŒ\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "52jb94h2hK4E",
        "outputId": "2bd29c84-626b-4c3c-d931-a3c1a3308a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 9.83 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "âŒ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Normal Ùˆ Abnormal Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-65c91c7e21a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âŒ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Normal Ùˆ Abnormal Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_dataset_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# ğŸ§¹ Ù…Ø±Ø­Ù„Ù‡ 3: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµØ§ÙˆÛŒØ±\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-65c91c7e21a1>\u001b[0m in \u001b[0;36mfind_dataset_path\u001b[0;34m(base_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'Normal'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'Abnormal'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âŒ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Normal Ùˆ Abnormal Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_dataset_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: âŒ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Normal Ùˆ Abnormal Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ù†Ø¯."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R Knee-Xray\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR4_oC2Ihd9U",
        "outputId": "1e850b51-ce67-42a1-d389-193432778318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'Knee-Xray': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "miZYEyJWh0Ey"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}