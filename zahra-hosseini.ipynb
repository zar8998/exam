{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvdJl_E1TK3m",
        "outputId": "0bd9b13c-9e26-4ff5-f18e-92919f628df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 20.13 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JziVSWgeh9xN",
        "outputId": "37c43b3c-b45f-4671-9f35-cd3e87eff636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Knee-X-ray' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "root_dir = \"/content/Knee-X-ray\"\n",
        "\n",
        "for root, dirs, files in os.walk(root_dir):\n",
        "    level = root.replace(root_dir, '').count(os.sep)\n",
        "    indent = ' ' * 4 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    sub_indent = ' ' * 4 * (level + 1)\n",
        "    for f in files[:5]:\n",
        "        print(f\"{sub_indent}{f}\")\n"
      ],
      "metadata": {
        "id": "xcKK2pV8h9z_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "الان شما دوباره مخزن `Knee-X-ray` رو دو بار کلون کردید، ولی هنوز چیزی از ساختار پوشه‌های داخل اون نشون ندادی، پس نمی‌دونیم تصاویر دقیقاً کجا قرار دارند.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ لطفاً این کد را همین الان اجرا کن تا ساختار فولدرها را چاپ کنیم:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "root_dir = \"/content/Knee-X-ray\"\n",
        "\n",
        "for root, dirs, files in os.walk(root_dir):\n",
        "    level = root.replace(root_dir, '').count(os.sep)\n",
        "    indent = ' ' * 4 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    sub_indent = ' ' * 4 * (level + 1)\n",
        "    for f in files[:5]:\n",
        "        print(f\"{sub_indent}{f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ⏭ بعد از اجرا:\n",
        "\n",
        "خروجی‌ای شبیه این می‌بینید:\n",
        "\n",
        "```\n",
        "Knee-X-ray/\n",
        "    dataset/\n",
        "        Normal/\n",
        "            image001.png\n",
        "        AbNormal/\n",
        "            image101.png\n",
        "```\n",
        "\n",
        "وقتی این خروجی رو اینجا بفرستی، دقیق می‌گم مسیر `dataset_path` باید چی باشه و بعد بریم سراغ ساخت `Custom Dataset` + نمایش نمونه تصاویر + آموزش مدل.\n",
        "\n",
        "بفرست تا بریم مرحله بعد.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "4J1fheH2h93C",
        "outputId": "a086c9ee-a59e-4f3d-eaa7-fc7598e3a56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '،' (U+060C) (<ipython-input-2-0eb82e7166a9>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0eb82e7166a9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    الان شما دوباره مخزن `Knee-X-ray` رو دو بار کلون کردید، ولی هنوز چیزی از ساختار پوشه‌های داخل اون نشون ندادی، پس نمی‌دونیم تصاویر دقیقاً کجا قرار دارند.\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '،' (U+060C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GJ7lQXQXh96P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CuAyXVg7h99o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogVpl9Yvcf07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "!apt install unrar -y > /dev/null\n",
        "!unrar x /content/Knee-X-ray/train.rar /content/Knee-X-ray/train > /dev/null\n",
        "!unrar x /content/Knee-X-ray/val.rar /content/Knee-X-ray/val > /dev/null\n",
        "!unrar x /content/Knee-X-ray/test.rar /content/Knee-X-ray/test > /dev/null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td7g8_F_TKs3",
        "outputId": "36dbb5de-1b28-4721-882b-7547d513ec70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 11.83 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/Knee-X-ray/train/train\"\n",
        "val_path = \"/content/Knee-X-ray/val/val\""
      ],
      "metadata": {
        "id": "nAgS3LHOTKoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# اگر هنوز نکردی، ابتدا گیت کلون کن\n",
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "\n",
        "# نصب unrar برای استخراج فایل‌های rar\n",
        "!apt install unrar -y > /dev/null\n",
        "\n",
        "# استخراج فایل‌های rar به فولدرهای جدا\n",
        "!unrar x /content/Knee-X-ray/train.rar /content/Knee-X-ray/train > /dev/null\n",
        "!unrar x /content/Knee-X-ray/val.rar /content/Knee-X-ray/val > /dev/null\n",
        "!unrar x /content/Knee-X-ray/test.rar /content/Knee-X-ray/test > /dev/null\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d_cMubzTKdo",
        "outputId": "b8c154c6-7ef0-40c3-b168-6a1f35c313dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 13.38 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 نصب و بارگیری اولیه\n",
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# 📁 بارگذاری تصاویر\n",
        "def load_images(base_path):\n",
        "    images, labels = [], []\n",
        "    for label_name in ['Normal', 'Abnormal']:\n",
        "        folder = os.path.join(base_path, label_name)\n",
        "        for img_name in os.listdir(folder):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            img = cv2.equalizeHist(img)  # افزایش کنتراست\n",
        "            img = img / 255.0  # نرمال‌سازی\n",
        "            images.append(img.reshape(224, 224, 1))\n",
        "            labels.append(0 if label_name == 'Normal' else 1)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "images, labels = load_images('Knee-X-ray/dataset')\n",
        "\n",
        "# ✅ افزایش داده‌ها\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "# 🧪 تقسیم داده‌ها\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "# بخش B - مدل‌ها\n",
        "\n",
        "# 📌 مدل‌های سنتی (SVM و Random Forest)\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_flat, y_train)\n",
        "svm_preds = svm_model.predict(X_test_flat)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X_train_flat, y_train)\n",
        "rf_preds = rf_model.predict(X_test_flat)\n",
        "\n",
        "# 📌 مدل CNN ساده\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "cnn_preds = (cnn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# 📌 یادگیری انتقالی با ResNet50\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "tl_model = Model(inputs=base_model.input, outputs=output)\n",
        "tl_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "tl_model.fit(X_train_rgb, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "tl_preds = (tl_model.predict(X_test_rgb) > 0.5).astype(\"int32\")\n",
        "\n",
        "# بخش C - ارزیابی مدل‌ها\n",
        "\n",
        "def get_scores(y_true, y_pred):\n",
        "    return {\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'F1-score': f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "results = {\n",
        "    'Model': ['SVM', 'Random Forest', 'CNN', 'ResNet50 Transfer'],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'Accuracy': [],\n",
        "    'F1-score': []\n",
        "}\n",
        "\n",
        "model_preds = [svm_preds, rf_preds, cnn_preds, tl_preds]\n",
        "for preds in model_preds:\n",
        "    scores = get_scores(y_test, preds)\n",
        "    for key in scores:\n",
        "        results[key].append(scores[key])\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n📊 جدول عملکرد مدل‌ها:\")\n",
        "print(df)\n",
        "\n",
        "print(\"\"\"\n",
        "🎯 چرا F1-score؟\n",
        "F1-score میانگین هماهنگ Precision و Recall است و برای داده‌های نامتوازن مناسب است.\n",
        "در وظیفه پزشکی، به‌ویژه وقتی که عدم تشخیص یک بیمار (False Negative) خطرناک است،\n",
        "F1-score ارزیابی دقیق‌تری از عملکرد مدل نسبت به Accuracy می‌دهد.\n",
        "\"\"\")\n",
        "\n",
        "# ✅ عدالت و اطمینان مدل:\n",
        "print(\"\"\"\n",
        "🔒 چگونه مدل عادلانه و قابل اعتماد بسازیم؟\n",
        "- استفاده از Stratified Split و Cross-Validation\n",
        "- استفاده از تکنیک‌های جلوگیری از Overfitting\n",
        "- تنظیم وزن کلاس‌ها یا استفاده از Oversampling\n",
        "- تحلیل عملکرد مدل روی زیرگروه‌های مختلف بیماران (مثلاً سن، جنسیت)\n",
        "\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "7OD3oDm1gpRX",
        "outputId": "add84075-045f-4dfd-d7f0-3b0f7bb5bd6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 16.19 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Knee-X-ray/dataset/Normal'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0e70d6010200>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Knee-X-ray/dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# ✅ افزایش داده‌ها\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-0e70d6010200>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(base_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Normal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Abnormal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Knee-X-ray/dataset/Normal'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/Knee-X-ray/train/train\"\n",
        "val_path = \"/content/Knee-X-ray/val/val\"\n"
      ],
      "metadata": {
        "id": "zA2wyseETKbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# افزایش داده برای تصاویر آموزش (تا مدل بهتر یاد بگیره)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,        # همه پیکسل‌ها رو بین 0 و 1 می‌کنیم\n",
        "    rotation_range=10,     # چرخش تصویر تا 10 درجه\n",
        "    width_shift_range=0.1, # جابجایی عرضی تا 10 درصد\n",
        "    height_shift_range=0.1,# جابجایی ارتفاعی تا 10 درصد\n",
        "    brightness_range=[0.8,1.2], # تغییر روشنایی\n",
        "    horizontal_flip=True,  # چرخش افقی تصویر\n",
        "    fill_mode='nearest'    # پر کردن جاهای خالی تصویر\n",
        ")\n",
        "\n",
        "# فقط نرمال‌سازی تصاویر اعتبارسنجی (بدون افزایش داده)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ساخت ژنراتور برای آموزش\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224,224), # اندازه تصاویر\n",
        "    batch_size=32,         # تعداد تصویر در هر مرحله\n",
        "    class_mode='binary',   # دو کلاس داریم\n",
        "    color_mode='grayscale' # تصاویر سیاه و سفید هستند\n",
        ")\n",
        "\n",
        "# ساخت ژنراتور برای اعتبارسنجی\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    color_mode='grayscale'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "7Hsmlc2MbAI_",
        "outputId": "808a3961-bcbe-43ab-8579-2b0dfa90c60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Knee-X-ray/train/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-643f840ce7c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# ساخت ژنراتور برای آموزش\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# اندازه تصاویر\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Knee-X-ray/train/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# === تحلیل مقدماتی داده‌ها ===\n",
        "\n",
        "# مسیر تصاویر سالم و غیرسالم\n",
        "normal_images = glob(\"Knee-X-ray/Normal/*.png\")\n",
        "abnormal_images = glob(\"Knee-X-ray/Abnormal/*.png\")\n",
        "\n",
        "print(f\"تعداد تصاویر سالم: {len(normal_images)}\")\n",
        "print(f\"تعداد تصاویر غیرسالم: {len(abnormal_images)}\")\n",
        "\n",
        "# نمایش نمونه تصویر اولیه\n",
        "def show_sample(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(\"Sample X-ray\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_sample(normal_images[0])\n",
        "\n",
        "\n",
        "# === پیش‌پردازش: نرمال‌سازی و حذف نویز ===\n",
        "\n",
        "def preprocess_image(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # نرمال‌سازی: تبدیل مقادیر پیکسل به [0, 1]\n",
        "    img = img / 255.0\n",
        "\n",
        "    # فیلتر گوسی برای حذف نویز نوری\n",
        "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "\n",
        "    return img\n",
        "\n",
        "# نمایش تصویر قبل و بعد پیش‌پردازش\n",
        "original = cv2.imread(normal_images[0], cv2.IMREAD_GRAYSCALE)\n",
        "processed = preprocess_image(normal_images[0])\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(original, cmap='gray')\n",
        "plt.title(\"Original\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(processed, cmap='gray')\n",
        "plt.title(\"Processed\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# === توجیه ریاضی نرمال‌سازی ===\n",
        "\n",
        "\"\"\"\n",
        "فرمول نرمال‌سازی تصویر:\n",
        "\n",
        "    Normalized = I / 255\n",
        "\n",
        "که در آن I مقدار پیکسل خام بین 0 تا 255 است.\n",
        "این عملیات باعث پایدار شدن گرادیان‌ها در شبکه عصبی و تسریع یادگیری می‌شود.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# === افزایش داده (Data Augmentation) ===\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,        # چرخش جزئی برای تنوع زاویه\n",
        "    width_shift_range=0.05,   # جابه‌جایی عرضی\n",
        "    height_shift_range=0.05,  # جابه‌جایی طولی\n",
        "    zoom_range=0.1,           # بزرگ‌نمایی جزئی\n",
        "    horizontal_flip=True,     # تقارن افقی\n",
        "    brightness_range=[0.9, 1.1] # افزایش/کاهش روشنایی\n",
        ")\n",
        "\n",
        "# نمایش نمونه‌ای از افزایش داده\n",
        "img = preprocess_image(normal_images[0])\n",
        "img = np.expand_dims(img, axis=(0, -1))  # برای ورودی ImageDataGenerator\n",
        "\n",
        "aug_iter = datagen.flow(img, batch_size=1)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(5):\n",
        "    aug_img = next(aug_iter)[0].squeeze()\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(aug_img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Aug {i+1}\")\n",
        "plt.suptitle(\"نمونه‌هایی از افزایش داده\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "S2Ao9ieBcYlL",
        "outputId": "c9d80531-5aab-430b-c224-bbd08f9096f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تعداد تصاویر سالم: 0\n",
            "تعداد تصاویر غیرسالم: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-376bc4ce5699>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mshow_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# فرض: data_images = [N, 224, 224] و labels = [0/1]\n",
        "# این داده‌ها را از مرحله A باید تولید کرده باشید.\n",
        "\n",
        "# برای مثال ساختگی:\n",
        "# data_images = np.array([...])\n",
        "# labels = np.array([0, 1, 0, 1, ...])\n",
        "\n",
        "# اضافه کردن بعد کانال برای CNN\n",
        "data_images = np.expand_dims(data_images, axis=-1)\n",
        "\n",
        "# تقسیم داده‌ها به train و test\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_images, labels, test_size=0.2, random_state=42, stratify=labels)\n"
      ],
      "metadata": {
        "id": "CYHnlAI4ftZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# برای ML داده‌ها باید به صورت فلت (ویژه‌ها در یک خط) باشند\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# مقیاس‌بندی ویژگی‌ها\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "# مدل SVM\n",
        "svm_model = SVC(kernel='rbf', C=1.0)\n",
        "svm_model.fit(X_train_flat, y_train)\n",
        "svm_preds = svm_model.predict(X_test_flat)\n",
        "\n",
        "# مدل Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X_train_flat, y_train)\n",
        "rf_preds = rf_model.predict(X_test_flat)\n",
        "\n",
        "# گزارش\n",
        "print(\"SVM Report:\")\n",
        "print(classification_report(y_test, svm_preds))\n",
        "\n",
        "print(\"Random Forest Report:\")\n",
        "print(classification_report(y_test, rf_preds))\n",
        "\n"
      ],
      "metadata": {
        "id": "LZWXCd7pfuo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "cnn_scores = cnn_model.evaluate(X_test, y_test)\n",
        "\n",
        "print(\"CNN Accuracy:\", cnn_scores[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "ujjyEiojf0ak",
        "outputId": "2923e75d-8421-41c3-df17-20c18dd4b209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-47b8f3d688d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mcnn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# تبدیل به 3 کاناله برای ورودی مدل‌های آماده\n",
        "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "base_model.trainable = False  # فریز کردن لایه‌ها\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "tl_model = Model(inputs=base_model.input, outputs=output)\n",
        "tl_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                 loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "tl_model.fit(X_train_rgb, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "tl_scores = tl_model.evaluate(X_test_rgb, y_test)\n",
        "\n",
        "print(\"Transfer Learning Accuracy:\", tl_scores[1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ErS6X59qf8s6",
        "outputId": "4a7e16d1-edaf-4241-e826-f0d64fe793af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c7de73ef8cb5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# تبدیل به 3 کاناله برای ورودی مدل‌های آماده\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mX_test_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧩 مرحله 1: کلون کردن دیتاست\n",
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "\n",
        "# 🧹 مرحله 2: وارد کردن کتابخانه‌ها\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 📂 مرحله 3: بارگذاری داده‌ها و پیش‌پردازش تصاویر\n",
        "def load_images(base_path):\n",
        "    images, labels = [], []\n",
        "    for label_name in ['Normal', 'Abnormal']:\n",
        "        folder = os.path.join(base_path, label_name)\n",
        "        if not os.path.exists(folder):\n",
        "            print(f\"⛔ پوشه پیدا نشد: {folder}\")\n",
        "            continue\n",
        "        for img_name in os.listdir(folder):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            img = cv2.equalizeHist(img)      # افزایش کنتراست\n",
        "            img = img / 255.0                # نرمال‌سازی\n",
        "            images.append(img.reshape(224, 224, 1))\n",
        "            labels.append(0 if label_name == 'Normal' else 1)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "images, labels = load_images('Knee-X-ray/dataset')\n",
        "\n",
        "# 📊 مرحله 4: تقسیم داده‌ها و افزایش داده\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# 🧠 مرحله 5: مدل‌های سنتی\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "svm_model = SVC()\n",
        "svm_model.fit(X_train_flat, y_train)\n",
        "svm_preds = svm_model.predict(X_test_flat)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100)\n",
        "rf_model.fit(X_train_flat, y_train)\n",
        "rf_preds = rf_model.predict(X_test_flat)\n",
        "\n",
        "# 🧠 مرحله 6: شبکه عصبی کانولوشنی (CNN)\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "cnn_preds = (cnn_model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# 🧠 مرحله 7: یادگیری انتقالی با ResNet50\n",
        "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "tl_model = Model(inputs=base_model.input, outputs=output)\n",
        "tl_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "tl_model.fit(X_train_rgb, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "tl_preds = (tl_model.predict(X_test_rgb) > 0.5).astype(\"int32\")\n",
        "\n",
        "# 📈 مرحله 8: ارزیابی مدل‌ها\n",
        "def get_scores(y_true, y_pred):\n",
        "    return {\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'F1-score': f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "results = {\n",
        "    'Model': ['SVM', 'Random Forest', 'CNN', 'ResNet50 Transfer'],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'Accuracy': [],\n",
        "    'F1-score': []\n",
        "}\n",
        "\n",
        "model_preds = [svm_preds, rf_preds, cnn_preds, tl_preds]\n",
        "for preds in model_preds:\n",
        "    scores = get_scores(y_test, preds)\n",
        "    for key in scores:\n",
        "        results[key].append(scores[key])\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"📊 جدول عملکرد مدل‌ها:\")\n",
        "print(df)\n",
        "\n",
        "# 📌 تحلیل نهایی\n",
        "print(\"\"\"\n",
        "✅ چرا F1-score؟\n",
        "F1-score برای داده‌های نامتوازن بهتر از Accuracy است، چون ترکیبی از Precision و Recall است.\n",
        "در کاربرد پزشکی، عدم تشخیص بیمار (False Negative) خطرناک است، پس F1-score معیار قابل‌اتکاتری محسوب می‌شود.\n",
        "\n",
        "✅ چطور مدل را قابل‌اعتمادتر کنیم؟\n",
        "- استفاده از Cross-validation یا Stratified split\n",
        "- جلوگیری از Overfitting با EarlyStopping، Dropout\n",
        "- بررسی عملکرد مدل روی زیرگروه‌های مختلف جمعیت (سن، جنسیت)\n",
        "- تنظیم وزن کلاس‌ها یا استفاده از SMOTE در مدل‌های سنتی\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4um9hrO7gGLT",
        "outputId": "3ddd7b09-49e4-47f8-e013-70d6e45c472b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Knee-X-ray' already exists and is not an empty directory.\n",
            "⛔ پوشه پیدا نشد: Knee-X-ray/dataset/Normal\n",
            "⛔ پوشه پیدا نشد: Knee-X-ray/dataset/Abnormal\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-edaf4b7e4824>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# 📊 مرحله 4: تقسیم داده‌ها و افزایش داده\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m datagen = ImageDataGenerator(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 مرحله 1: پاک‌سازی و کلون دیتاست\n",
        "!rm -rf Knee-X-ray\n",
        "!git clone https://github.com/F-Aghaeipoor/Knee-X-ray.git\n",
        "\n",
        "# 📦 وارد کردن کتابخانه‌ها\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 📂 مرحله 2: یافتن مسیر پوشه‌ها\n",
        "def find_dataset_path(base_dir='Knee-X-ray'):\n",
        "    for root, dirs, files in os.walk(base_dir):\n",
        "        if 'Normal' in dirs and 'Abnormal' in dirs:\n",
        "            return root\n",
        "    raise Exception(\"❌ پوشه‌های Normal و Abnormal پیدا نشدند.\")\n",
        "\n",
        "dataset_path = find_dataset_path()\n",
        "\n",
        "# 🧹 مرحله 3: بارگذاری و پیش‌پردازش تصاویر\n",
        "def load_images(base_path):\n",
        "    images, labels = [], []\n",
        "    for label_name in ['Normal', 'Abnormal']:\n",
        "        folder = os.path.join(base_path, label_name)\n",
        "        for img_name in os.listdir(folder):\n",
        "            img_path = os.path.join(folder, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            img = cv2.equalizeHist(img)\n",
        "            img = img / 255.0\n",
        "            images.append(img.reshape(224, 224, 1))\n",
        "            labels.append(0 if label_name == 'Normal' else 1)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "images, labels = load_images(dataset_path)\n",
        "\n",
        "# 🔄 مرحله 4: تقسیم داده‌ها + افزایش داده\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# 🎯 مرحله 5: مدل‌های سنتی (SVM + RandomForest)\n",
        "X_train_flat = X_train.reshape(len(X_train), -1)\n",
        "X_test_flat = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = scaler.fit_transform(X_train_flat)\n",
        "X_test_flat = scaler.transform(X_test_flat)\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train_flat, y_train)\n",
        "svm_preds = svm.predict(X_test_flat)\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train_flat, y_train)\n",
        "rf_preds = rf.predict(X_test_flat)\n",
        "\n",
        "# 🧠 مرحله 6: شبکه CNN ساده\n",
        "cnn = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,1)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "cnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "cnn_preds = (cnn.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "# 🧠 مرحله 7: یادگیری انتقالی با ResNet50\n",
        "X_train_rgb = np.repeat(X_train, 3, axis=-1)\n",
        "X_test_rgb = np.repeat(X_test, 3, axis=-1)\n",
        "\n",
        "base = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "base.trainable = False\n",
        "x = GlobalAveragePooling2D()(base.output)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "resnet_model = Model(inputs=base.input, outputs=output)\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "resnet_model.fit(X_train_rgb, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
        "resnet_preds = (resnet_model.predict(X_test_rgb) > 0.5).astype(\"int32\")\n",
        "\n",
        "# 📈 مرحله 8: گزارش ارزیابی\n",
        "def get_scores(y_true, y_pred):\n",
        "    return {\n",
        "        'Precision': precision_score(y_true, y_pred),\n",
        "        'Recall': recall_score(y_true, y_pred),\n",
        "        'Accuracy': accuracy_score(y_true, y_pred),\n",
        "        'F1-score': f1_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "results = {\n",
        "    'Model': ['SVM', 'Random Forest', 'CNN', 'ResNet50 Transfer'],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'Accuracy': [],\n",
        "    'F1-score': []\n",
        "}\n",
        "for preds in [svm_preds, rf_preds, cnn_preds, resnet_preds]:\n",
        "    scores = get_scores(y_test, preds)\n",
        "    for key in scores:\n",
        "        results[key].append(scores[key])\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"📊 ارزیابی نهایی مدل‌ها:\\n\")\n",
        "print(df)\n",
        "\n",
        "# 📝 توضیح نهایی\n",
        "print(\"\"\"\n",
        "✅ چرا F1-score مهم است؟\n",
        "F1-score هم تعادل Precision و هم Recall را درنظر می‌گیرد. در مسائل پزشکی مانند تشخیص بیماری، اگر فقط دقت یا فقط Recall مهم باشد، ممکن است بیمار واقعی تشخیص داده نشود یا فرد سالم به اشتباه بیمار اعلام شود.\n",
        "\n",
        "✅ چطور مدل را قابل اعتمادتر کنیم؟\n",
        "- استفاده از Stratified Split\n",
        "- EarlyStopping و Dropout برای جلوگیری از Overfitting\n",
        "- بررسی عملکرد روی زیرگروه‌ها (مانند جنسیت یا سن)\n",
        "- افزایش داده‌ها با حفظ ویژگی‌های واقعی تصاویر پزشکی\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "52jb94h2hK4E",
        "outputId": "2bd29c84-626b-4c3c-d931-a3c1a3308a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Knee-X-ray'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 31.75 MiB | 9.83 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "❌ پوشه‌های Normal و Abnormal پیدا نشدند.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-65c91c7e21a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"❌ پوشه‌های Normal و Abnormal پیدا نشدند.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_dataset_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# 🧹 مرحله 3: بارگذاری و پیش‌پردازش تصاویر\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-65c91c7e21a1>\u001b[0m in \u001b[0;36mfind_dataset_path\u001b[0;34m(base_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'Normal'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'Abnormal'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"❌ پوشه‌های Normal و Abnormal پیدا نشدند.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_dataset_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: ❌ پوشه‌های Normal و Abnormal پیدا نشدند."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R Knee-Xray\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR4_oC2Ihd9U",
        "outputId": "1e850b51-ce67-42a1-d389-193432778318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'Knee-Xray': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "miZYEyJWh0Ey"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}